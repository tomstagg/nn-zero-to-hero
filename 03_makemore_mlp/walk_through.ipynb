{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1159d254-290a-42b0-a280-bc9543a7069d",
   "metadata": {},
   "source": [
    "# makemore MLP\n",
    "If we take more context, more characters, it quickly get's unmanageable. e.g. 4 chars = 27^3 ~ 19200 possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10395900-4daf-4ac7-b61e-6bf5d971c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn.functional as F, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbccd54c-4d68-4004-b151-5a424ee2a9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"../names.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491bf3e1-400d-4367-b647-d39b534f694a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "850e29cd-c257-4f0a-9756-b704b6f5870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary of characters and mappings to and from ints\n",
    "chars = sorted(list(set(''.join(words))) + ['.'])\n",
    "itos = {idx: ch for idx, ch in enumerate(chars)}\n",
    "stoi = {v:k for k, v in itos.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5c7503-0343-458f-8885-0e559142f924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... --> e\n",
      "..e --> m\n",
      ".em --> m\n",
      "emm --> a\n",
      "mma --> .\n",
      "olivia\n",
      "... --> o\n",
      "..o --> l\n",
      ".ol --> i\n",
      "oli --> v\n",
      "liv --> i\n",
      "ivi --> a\n",
      "via --> .\n",
      "ava\n",
      "... --> a\n",
      "..a --> v\n",
      ".av --> a\n",
      "ava --> .\n",
      "isabella\n",
      "... --> i\n",
      "..i --> s\n",
      ".is --> a\n",
      "isa --> b\n",
      "sab --> e\n",
      "abe --> l\n",
      "bel --> l\n",
      "ell --> a\n",
      "lla --> .\n",
      "sophia\n",
      "... --> s\n",
      "..s --> o\n",
      ".so --> p\n",
      "sop --> h\n",
      "oph --> i\n",
      "phi --> a\n",
      "hia --> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(f\"{''.join(itos[i] for i in context)} --> {itos[ix]}\")\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa55360-6b4f-45a3-8be2-240fe5025025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a51df1-a6f6-4259-956d-d59028645ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tagent: create embedding matrix. We are embedding 27 characters in a 2D embedding\n",
    "C = torch.randn((27,2))\n",
    "C.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e0ba977-6567-4029-b3ba-383d34b319f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_method = F.one_hot(torch.tensor(5), num_classes=27).float() @ C # must have same datatype, one_hot default is log\n",
    "index_directly = C[5] \n",
    "torch.equal(one_hot_method, index_directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "634acd7c-a6cd-4f5c-ac1e-accd8764140c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0599, 0.4453])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "35b3aaa1-919b-415f-9f51-4e81f4a89827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0599,  0.4453],\n",
       "        [-0.7089, -0.5231],\n",
       "        [-0.7756, -0.7479]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index using lists\n",
    "C[[5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c004c073-a5cb-4122-891f-c3ee67b0a217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0599,  0.4453],\n",
       "        [-0.7089, -0.5231],\n",
       "        [-0.7756, -0.7479],\n",
       "        [-0.7756, -0.7479],\n",
       "        [-0.7756, -0.7479]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can index multiple times and get result in multiple\n",
    "C[torch.tensor([5,6,7,7,7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4ec885b5-7895-4289-b342-bb7a436ca71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fc9f088-71a7-4400-8d31-12eb4c67afa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape # gets embedding vector for each X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d8dd1920-777a-414b-a6ed-78aa18404f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# integer is 1\n",
    "X[13,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "29eb5a87-95f7-42e8-be31-6380002d3082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.6016,  1.6488]), tensor([-0.6016,  1.6488]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the integer at that location of C is the same\n",
    "C[X][13,2], C[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9ec47094-dd3a-47b4-8bbd-8ae1d764c1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6016,  1.6488])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2fa5ecb0-c091-44e6-be35-46124e11cdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "69be90a7-cc0b-4555-955d-05a498821baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup first layer\n",
    "W1 = torch.rand((6,100))\n",
    "b1 = torch.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "90f64c5b-88d1-4987-890d-18a9675e90e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tangent: different way to use torch and torch internals\n",
    "# want to matmul emb @ W1 but they are different sizes: (32,3,2) @ (6,100). \n",
    "# need to transform the emb to do this:\n",
    "first_char_embed = emb[:,0,:]\n",
    "second_char_embed = emb[:,1,:]\n",
    "third_char_embed = emb[:,2,:]\n",
    "\n",
    "# we want to concat across dim 1\n",
    "torch.cat((first_char_embed,second_char_embed, third_char_embed), dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "659a936e-b6c3-4608-93e4-fa9d100d01cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# above works, but we'd need to change this code if we use a bigger block_size, instead can use unbind:\n",
    "# unbind will return a tuple of all slices along a given dimension\n",
    "torch.unbind(emb, 1)\n",
    "torch.unbind(emb,1)[0].shape # 3 slices in tuple with shape 32, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7aa73f26-305f-40d2-af5d-5f3a7792cf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 6])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), dim=1).shape # but this inefficient as a whole new tensor is created for this op, uses more memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "01efb46d-3e5c-451c-9c36-d5846346418d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a better way:\n",
    "a = torch.arange(18)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d620c692-f62c-439c-9432-bc4b5d9f73cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6cc7b385-1581-40fe-af22-604b5b931394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12, 13, 14, 15, 16, 17]]),\n",
       " tensor([[[ 0,  1],\n",
       "          [ 2,  3],\n",
       "          [ 4,  5]],\n",
       " \n",
       "         [[ 6,  7],\n",
       "          [ 8,  9],\n",
       "          [10, 11]],\n",
       " \n",
       "         [[12, 13],\n",
       "          [14, 15],\n",
       "          [16, 17]]]),\n",
       " tensor([[ 0,  1],\n",
       "         [ 2,  3],\n",
       "         [ 4,  5],\n",
       "         [ 6,  7],\n",
       "         [ 8,  9],\n",
       "         [10, 11],\n",
       "         [12, 13],\n",
       "         [14, 15],\n",
       "         [16, 17]]),\n",
       " tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12, 13, 14, 15, 16, 17]]))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(2,9), a.view(3,3, 2), a.view(9,2), a.view(-1,9) # -1 means whatever is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c37a6db3-c6cf-4c40-87c2-80ed57ec5b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       "[torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.storage() #physical storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "705ad5a9-71ef-442d-ba87-6d25483941b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), dim=1) == emb.view(32,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fa264917-05a0-4abc-9f84-71e44a0cfc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9032,  4.1361,  4.5650,  ...,  1.9633,  2.6685,  4.3327],\n",
       "        [ 2.5082,  3.9130,  4.3207,  ...,  1.9953,  2.3136,  4.0329],\n",
       "        [ 0.7555,  2.4680,  3.0508,  ...,  2.0188,  0.9817,  2.4596],\n",
       "        ...,\n",
       "        [-0.8331, -1.2928, -0.7480,  ...,  0.3800,  1.0624,  0.5667],\n",
       "        [-0.9798, -0.5661, -1.9993,  ..., -0.4268, -1.9186, -0.0536],\n",
       "        [-0.6883,  0.9239,  0.4850,  ...,  1.1965,  0.1382,  1.4256]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################\n",
    "emb.view(32,6) @ W1 + b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "359ad983-f280-4d0d-9cb8-33e0f8a40317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to deal with dim 0 being variable for X:\n",
    "h1 = emb.view(32,6) @ W1 + b1\n",
    "h2 = emb.view(emb.shape[0],6) @ W1 + b1\n",
    "h3 = emb.view(-1,6) @ W1 + b1 #  -1 means whatever is left.\n",
    "torch.equal(h1,h2), torch.equal(h1,h3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c8994136-b9a9-407b-8615-df100f0f7773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################## \n",
    "# back to the hidden layer:\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "faf35774-f036-4b40-be40-6ad81b7552cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100]), torch.Size([32, 100]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check bias broadcasting when adding:\n",
    "b1.shape, (emb.view(-1,6) @ W1).shape\n",
    "# emb @ w1 32, 100\n",
    "# b1        1, 100 << start at trailing dim, prepend 1 to the dims of the tensor\n",
    "# copied the b vertically to all the rows, which is what we want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "df885fc7-49a0-4621-ba60-7052e96a15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.rand((100,27))\n",
    "b2 = torch.rand(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e18ffd33-b44e-4914-9165-baf6a5e88744",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4b14e165-f2a1-4df0-9f90-52c020303f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "3d754fe7-e263-4655-a58f-5b0d1da3a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5324d56f-597b-4aa5-a1e8-d31f81b81bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = counts / counts.sum(1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "57d3d7ba-a096-43be-bc0c-d40a3db00d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b0a0a286-cf72-4147-b1d2-6341d8d04b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "71143cac-c182-49aa-b675-fe6b04302e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -prob[torch.arange(32), Y].log().mean() # neg log liklihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d900727-d3f6-4f6a-afe2-85bfbda1309a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- \n",
    "# bring the above together\n",
    "X.shape, Y.shape # dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3943c1d5-74dd-4ec1-9f17-ef92efedea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.rand((27,2), generator = g)\n",
    "W1 = torch.rand((6,100), generator=g)\n",
    "b1 = torch.rand(100, generator=g)\n",
    "W2 = torch.rand((100,27), generator=g)\n",
    "b2 = torch.rand(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "fe078789-e40a-41c6-b962-fb2a061f5d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0534a10c-c831-4c44-9cdc-61a1f91ae658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3572)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32,27)\n",
    "counts = logits.exp()\n",
    "prob = counts / counts.sum(1, keepdim=True)\n",
    "loss = - prob[torch.arange(32), Y].log().mean()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "219df0e3-e2bd-4faa-a269-fb61918a1d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.3572)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tangent: cross_entropy means: \n",
    "# - creating the intermediate steps and do them together using fused kernels, \n",
    "# - expressions can take a simplier form, similar to forward and backward pass of tanh()\n",
    "# - cross_entry can be much better numericall behaved i.e dealing wtih higher logits\n",
    "\n",
    "F.cross_entropy(logits, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9deaf8e3-9720-4360-a4a9-5f7b5e09b1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., nan])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_entropy performed much better numericall behaved. As we are exp() the logits, if the logits are high (100) can get nan, -100 is ok:\n",
    "logits = torch.tensor([-100, -3, 0, 100])\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "fac9ec3b-568a-444e-be5e-8bfa1dac47a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5079e-05, 3.3309e-04, 6.6903e-03, 9.9293e-01])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can add offset to this and get the same answer:\n",
    "logits = torch.tensor([-5, -3, 0, 5]) - 10\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "96f8e90e-e206-4b6f-a964-9d554c573e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5079e-05, 3.3309e-04, 6.6903e-03, 9.9293e-01])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as: \n",
    "logits = torch.tensor([-5, -3, 0, 5]) - 20\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "96dbfae6-b2e4-4155-8256-ec59afe54a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.4013e-45, 3.7835e-44, 1.0000e+00])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.tensor([-100, -3, 0, 100]) - 100\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "2f1c2240-477a-4cce-891f-d4609c6d0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "f738128a-b4a8-46ae-a83e-d16b22cf59f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2525448799133301\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "for _ in range(1000):\n",
    "    # forward pass\n",
    "    emb = C[X] # (32,3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32,27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    \n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "45db5f9b-fba8-43bc-a6f6-fc609ae8e549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.max(\n",
       " values=tensor([ 43.6240,  64.4105,  58.8915,  68.1924,   0.9242,  43.6240,  17.9316,\n",
       "          11.4024, -17.6828,  33.6481,  45.3112,   8.1901,  43.6240,  23.4733,\n",
       "          43.4074, -12.2734,  43.6240,  41.4969,  60.3677,  27.2958,  12.0153,\n",
       "          25.7188,  35.0194,  61.3420, -11.1273,  43.6240,  55.2428,  36.2484,\n",
       "          31.1155,  21.6926,  57.4884,  13.5841], grad_fn=<MaxBackward0>),\n",
       " indices=tensor([ 1, 13, 13,  1,  0,  1, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  1, 19,\n",
       "          1,  2,  5, 12, 12,  1,  0,  1, 15, 16,  8,  9,  1,  0])),\n",
       " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return the max index for each row and compare it to the expected index. \n",
    "# so some match but other's dont. e.g index 0, as ... predicts either e,o,a,i or s all are possible, from the training set.\n",
    "# this means it's not possilbe to get loss to 0, and overfit\n",
    "logits.max(1),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "36963fbe-a6e6-42d5-aa77-392cd7c1606c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3, 4],\n",
       "         [5, 6, 7, 8, 9]]),\n",
       " torch.return_types.max(\n",
       " values=tensor([4, 9]),\n",
       " indices=tensor([4, 4])))"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how max works\n",
    "x = torch.arange(10)\n",
    "y = x.view(-1,5)\n",
    "y, y.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ee8571-06d0-42d8-b594-f648753f4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the full dataset\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67245186-40b5-47b6-b36d-e78a2368c66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4685915-408b-48bc-b933-514de14da178",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.rand((27,2), generator = g)\n",
    "W1 = torch.rand((6,100), generator=g)\n",
    "b1 = torch.rand(100, generator=g)\n",
    "W2 = torch.rand((100,27), generator=g)\n",
    "b2 = torch.rand(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8fda094-7004-4963-82ab-c49d41445acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e52968-7737-453f-b6cd-3a88c596d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "15f93519-f375-4fca-ac85-2310ec261ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.668493747711182\n",
      "5.1129469871521\n",
      "3.8875772953033447\n",
      "3.495539665222168\n",
      "3.3378922939300537\n",
      "3.225546360015869\n",
      "3.1348354816436768\n",
      "3.0562543869018555\n",
      "2.988011598587036\n",
      "2.932504177093506\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    # forward pass\n",
    "    emb = C[X] # (32000,3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32000, 100)\n",
    "    logits = h @ W2 + b2 # (32000,27)\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "8781ff8e-1826-4a03-882f-3e98f3745656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([119797, 135103,  68519,  78310,   1849,  10334, 175244,  22232,  84835,\n",
       "        132659,  57062, 195604,  94142, 157832,  64927,  78522,  13348,  31850,\n",
       "        201084, 144172,  40730,  14861,  38417, 140192,  83381, 157992,  29477,\n",
       "        129486, 162059,  81486,  70888, 223125])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mini-batch to reduce training time, randomly select a batch from the training set and train on that:\n",
    "torch.randint(0, X.shape[0], (32,)) # low, high and size (as tuple) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9299a51-24b0-4585-8ba4-f29d6a3d6fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9648590087890625\n",
      "2.6528027057647705\n",
      "2.8100643157958984\n",
      "2.866823196411133\n",
      "2.707019567489624\n",
      "2.848673105239868\n",
      "3.189858913421631\n",
      "2.8352770805358887\n",
      "2.7900948524475098\n",
      "3.111520528793335\n",
      "2.859539031982422\n",
      "3.046997547149658\n",
      "3.02547287940979\n",
      "2.5750844478607178\n",
      "2.832350254058838\n",
      "2.7211475372314453\n",
      "3.0934629440307617\n",
      "3.118736505508423\n",
      "2.8435776233673096\n",
      "2.912137508392334\n",
      "3.017094850540161\n",
      "2.841599464416504\n",
      "3.002427101135254\n",
      "2.844202756881714\n",
      "2.8834824562072754\n",
      "3.145188331604004\n",
      "2.7380101680755615\n",
      "2.755811929702759\n",
      "2.7141408920288086\n",
      "2.876512050628662\n",
      "2.6551740169525146\n",
      "3.136817693710327\n",
      "2.709643840789795\n",
      "2.808337450027466\n",
      "3.1058692932128906\n",
      "2.8435585498809814\n",
      "2.694821357727051\n",
      "2.602365732192993\n",
      "2.595930337905884\n",
      "2.8852570056915283\n",
      "2.8886642456054688\n",
      "2.5396482944488525\n",
      "2.806668281555176\n",
      "2.8390884399414062\n",
      "2.9100406169891357\n",
      "3.0885636806488037\n",
      "2.7862789630889893\n",
      "2.788360595703125\n",
      "3.2058510780334473\n",
      "2.909269332885742\n",
      "3.024956226348877\n",
      "2.8851728439331055\n",
      "2.802968740463257\n",
      "2.913724660873413\n",
      "2.8505969047546387\n",
      "2.8597054481506348\n",
      "2.5673582553863525\n",
      "2.7250008583068848\n",
      "2.761090040206909\n",
      "2.8558292388916016\n",
      "2.921627998352051\n",
      "2.7857470512390137\n",
      "2.91330885887146\n",
      "2.7351555824279785\n",
      "2.9041287899017334\n",
      "2.7087552547454834\n",
      "2.452869176864624\n",
      "2.916673421859741\n",
      "2.6153576374053955\n",
      "3.1411566734313965\n",
      "3.072751998901367\n",
      "2.8597607612609863\n",
      "2.8059163093566895\n",
      "2.6421072483062744\n",
      "2.8697354793548584\n",
      "2.5018656253814697\n",
      "3.029822826385498\n",
      "2.890805959701538\n",
      "2.7181568145751953\n",
      "2.5357964038848877\n",
      "2.641486644744873\n",
      "2.5405988693237305\n",
      "2.7640323638916016\n",
      "2.647204875946045\n",
      "2.978635311126709\n",
      "3.020946502685547\n",
      "2.746610403060913\n",
      "2.931105136871338\n",
      "2.834721803665161\n",
      "2.923452854156494\n",
      "2.9385228157043457\n",
      "2.5928940773010254\n",
      "2.6164710521698\n",
      "2.8000614643096924\n",
      "2.748854637145996\n",
      "2.676482915878296\n",
      "2.8021626472473145\n",
      "2.6596791744232178\n",
      "2.4405148029327393\n",
      "2.7111072540283203\n"
     ]
    }
   ],
   "source": [
    "# why minibatch. minibatch will get an approximate gradient rather than exact and it's better to make many steps using \n",
    "# an approx gradient, rather than few steps using a more accurate gradient.\n",
    "for _ in range(100):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) # minibatch of 32 items\n",
    "    # forward pass\n",
    "    emb = C[X[ix]] # (32,3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32,27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # use minibatch index to get labelled result\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25bf24a8-b8f2-4b78-800b-ad86bdf654ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7607, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss for the full training set\n",
    "emb  = C[X] \n",
    "h = torch.tanh(emb.view(-1,6) @ W1 + b1)\n",
    "logits = h @ W2 + b2\n",
    "loss = F.cross_entropy(logits, Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3224ab3f-fc16-4675-b640-b3afbeb785c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rates, checking rate\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.rand((27,2), generator = g)\n",
    "W1 = torch.rand((6,100), generator=g)\n",
    "b1 = torch.rand(100, generator=g)\n",
    "W2 = torch.rand((100,27), generator=g)\n",
    "b2 = torch.rand(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6e33bfb-c312-42fc-b173-b3926a8d05ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.227935791015625\n",
      "11.546402931213379\n",
      "33.976444244384766\n",
      "19.65176010131836\n",
      "19.65262794494629\n",
      "15.977632522583008\n",
      "11.893694877624512\n",
      "14.985189437866211\n",
      "13.15888500213623\n",
      "13.031699180603027\n",
      "10.335827827453613\n",
      "10.280573844909668\n",
      "6.444364547729492\n",
      "6.754821300506592\n",
      "6.7885637283325195\n",
      "5.312748432159424\n",
      "5.288608551025391\n",
      "7.065597057342529\n",
      "8.048784255981445\n",
      "6.6396307945251465\n",
      "10.49025821685791\n",
      "13.85434341430664\n",
      "8.11581802368164\n",
      "5.430596828460693\n",
      "6.216933727264404\n",
      "8.831623077392578\n",
      "8.386439323425293\n",
      "8.574119567871094\n",
      "9.745198249816895\n",
      "6.018150806427002\n",
      "8.387862205505371\n",
      "8.014059066772461\n",
      "6.881567478179932\n",
      "6.885052680969238\n",
      "6.732348442077637\n",
      "5.167070388793945\n",
      "6.403532981872559\n",
      "4.921173572540283\n",
      "3.718583106994629\n",
      "3.827099323272705\n",
      "3.861178398132324\n",
      "4.794559955596924\n",
      "5.1293864250183105\n",
      "6.014892578125\n",
      "3.825348138809204\n",
      "6.906620502471924\n",
      "11.068583488464355\n",
      "8.912542343139648\n",
      "5.730525970458984\n",
      "8.777033805847168\n",
      "6.629668712615967\n",
      "6.366147041320801\n",
      "8.535271644592285\n",
      "8.418272972106934\n",
      "4.983580112457275\n",
      "4.272430896759033\n",
      "4.563830852508545\n",
      "6.451292037963867\n",
      "4.956859111785889\n",
      "4.38275671005249\n",
      "5.2170796394348145\n",
      "4.44444465637207\n",
      "6.625943183898926\n",
      "4.606488227844238\n",
      "6.422756195068359\n",
      "4.9953508377075195\n",
      "5.182780742645264\n",
      "6.564647674560547\n",
      "5.376732349395752\n",
      "6.414882659912109\n",
      "4.348068714141846\n",
      "4.241327285766602\n",
      "4.710427284240723\n",
      "5.124814987182617\n",
      "8.33586597442627\n",
      "7.031230926513672\n",
      "9.67568302154541\n",
      "5.170086860656738\n",
      "4.102700233459473\n",
      "4.885436058044434\n",
      "5.45736026763916\n",
      "4.327210426330566\n",
      "4.871396541595459\n",
      "3.5579898357391357\n",
      "4.385597229003906\n",
      "4.278572082519531\n",
      "3.515432119369507\n",
      "4.207188129425049\n",
      "3.9544568061828613\n",
      "5.281819820404053\n",
      "3.787447690963745\n",
      "4.84480094909668\n",
      "3.456510543823242\n",
      "3.2291343212127686\n",
      "4.036967754364014\n",
      "5.079975128173828\n",
      "4.262111663818359\n",
      "4.634123802185059\n",
      "5.222930431365967\n",
      "4.629873275756836\n",
      "4.629873275756836\n"
     ]
    }
   ],
   "source": [
    "# find the lower and upper bounds, a search range, where loss does not decrease anymore\n",
    "# 0.0001 loss doesn't go down, but does at 0.001, \n",
    "\n",
    "LEARNING_RATE = 1 # tried 0.001, 0.01, 0.1, 1, 10\n",
    "for _ in range(100):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, X.shape[0], (32,)) # minibatch of 32 items\n",
    "    # forward pass\n",
    "    emb = C[X[ix]] # (32,3,2)\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32,27)\n",
    "    loss = F.cross_entropy(logits, Y[ix]) # use minibatch index to get labelled result\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for p in parameters:\n",
    "        p.data += -LEARNING_RATE * p.grad \n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83152985-0275-40d5-9644-f1557e1b4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
